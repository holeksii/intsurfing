{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.0`\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@6238a68b"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "    .builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpeopleFile\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"/host/storage/people.csv\"\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstname: string, lastname: string ... 2 more fields]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val peopleFile = \"/host/storage/people.csv\"\n",
    "\n",
    "val df = spark\n",
    "    .read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(peopleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count all people with the same last name by every state from people.csv file and displays the result as a percentage for every state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------------------+\n",
      "|     state| lastname|lastNamePercentageByState|\n",
      "+----------+---------+-------------------------+\n",
      "|California|   Watson|                     20.0|\n",
      "|   Florida|    Baker|                     20.0|\n",
      "|   Florida|    Myers|                     10.0|\n",
      "|California|   Walker|                     20.0|\n",
      "|California|   Batres|                     10.0|\n",
      "|   Florida|    Baird|                     10.0|\n",
      "|   Florida|    Jones|                     10.0|\n",
      "|   Florida|Ratchford|                     10.0|\n",
      "|   Florida|   Foster|                     10.0|\n",
      "|California|  Johnson|                     10.0|\n",
      "|   Florida| Harrison|                     30.0|\n",
      "|California|   Turner|                     40.0|\n",
      "+----------+---------+-------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcountByState\u001b[39m: \u001b[32mDataFrame\u001b[39m = [state: string, countByState: bigint]\n",
       "\u001b[36mcountByLastNameAndState\u001b[39m: \u001b[32mDataFrame\u001b[39m = [state: string, lastname: string ... 1 more field]\n",
       "\u001b[36mlastNamePercentageByState\u001b[39m: \u001b[32mDataFrame\u001b[39m = [state: string, lastname: string ... 1 more field]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val countByState = df\n",
    "    .groupBy(\"state\")\n",
    "    .agg(count(\"state\").as(\"countByState\"))\n",
    "\n",
    "val countByLastNameAndState = df\n",
    "    .groupBy(\"state\", \"lastname\")\n",
    "    .agg(count(\"lastname\").as(\"countByLastNameAndState\"))\n",
    "\n",
    "val lastNamePercentageByState = countByLastNameAndState\n",
    "    .join(countByState, \"state\")\n",
    "    .withColumn(\n",
    "        \"lastNamePercentageByState\",\n",
    "        $\"countByLastNameAndState\" / $\"countByState\" * 100\n",
    "    )\n",
    "    .select(\"state\", \"lastname\", \"lastNamePercentageByState\")\n",
    "\n",
    "lastNamePercentageByState.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to different files for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastNamePercentageByState\n",
    "    .write\n",
    "    .partitionBy(\"state\")\n",
    "    .json(\"/host/storage/peopleByLastnameFromState\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
